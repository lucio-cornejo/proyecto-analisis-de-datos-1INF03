---
title: Primer avance
date: '2022-06-06'
format:
  html:
    self-contained: true
    theme: cerulean
    toc: true
    toc-depth: 4
    code-tools: true
    toc-title: Tabla de contenido
---

```{r}
#| include: false

library(reticulate)
use_python("C:/Python39/python.exe")
```

## Integrantes

* Lucio Cornejo
* Andrea Mejia
* Claudia Vivas
* Renzo Richle

1. [Paso 2](#paso-2)
    - [Adquisición de Datos](#adquisicion-de-datos)
2. [Paso 3](#paso-3)
    - [Entendimiento de los datos](#entendimiento-de-los-datos)
    - [Duplicados](#duplicados)
    - [Vacios](#vacios)
    - [Medidas de resumen para variables numéricas](#medidas-de-resumen-para-variables-numericas)
    - [Medidas de resumen para variables categóricas](#medidas-de-resumen-para-variables-categoricas)
    - [Tratamiento de datos atípicos](#tratamiento-de-datos-atipicos)
        - [Outliers por exceso](#outliers-por-exceso)
        - [Outliers por defecto](#outliers-por-defecto)
        - [Separar la base en atipicos y no atipicos](#separar-la-base-en-atipicos-y-no-atipicos)
    

## Paso 2

### Adquisicion de Datos

```{python}
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
```

```{python}
# Cargamos la base de datos

# tracks = pd.read_csv(r'F:\2022-1\Analisis de datos\Tarea Ac
# ademica\archive\tracks.csv')

tracks = pd.read_csv("../datos/tracks.csv")
```

```{python}
tracks.head()
```

## Paso 3

### Entendimiento de los datos

```{python}
print('La base tiene',tracks.shape[0], 'filas y', tracks.shape[1], 'columnas')
```

```{python}
print('Las columnas se la base se llaman:',tracks.columns.to_list())
```

```{python}
tracks.dtypes
print('Se tiene los siguientes tipos de datos por columna: \n',tracks.dtypes)
```

## INSERTAR DESCRIPCIÓN DE CADA VARIABLE

```{python}
# Descripción de los datos
tracks.info()
```

```{python}
type(tracks.columns)
```

```{python}
# Convertimos las variables object a variables string 

tracks[['id', 'name', 'artists', 'id_artists']] = tracks[['id', 'name', 'artists', 'id_artists']].astype('string')
```

```{python}
# Convertimos la variable 'release_date' a datetime64[ns]
tracks['release_date'] = pd.to_datetime(tracks['release_date'], format="%Y-%m-%d")
```

## Duplicados

```{python}
# Omitimos duplicados 
print(tracks.shape)
tracks.drop_duplicates(subset = 'id', inplace=True)
print(tracks.shape)
```

Se observa que los datos no tienen filas con valores duplicados, es decir, no existen registros repetidos.

## Vacios

```{python}
# Contabilizamos vacíos
vacios = pd.DataFrame(tracks.isnull().sum()).sort_values(0,ascending=True)
vacios.columns = ['vacios']
vacios['vacios%'] = round(vacios['vacios']/tracks.shape[0], 2)*100
vacios 
```

La columna "name" almacena 71 valores vacios.

## ¿PORQUE EXCLUIMOS LOS VALORES VACIOS? MEJOR AUN NO ELIMINAMOS PARA HACER LAS ESTADISTICAS DESCRIPTICVAS

```{python}
# Excluimos vacíos
# print(tracks.shape) 
# tracks.dropna(inplace=True)
# print(tracks.shape)
```

### Medidas de resumen para variables numericas

```{python}
# División de variables numéricas y categóricas
dfnum = tracks.select_dtypes(include=['float64', 'int64'])
dfcat = tracks.select_dtypes(exclude=['float64', 'int64'])
```

```{python}
print('Variables categóricas', dfcat.shape)
print('Variables numéricas', dfnum.shape)
```

```{python}
# estadisticas desciptivas para las variables numéricas
dfnum.describe()
```

## COMENTAR LAS CARACTERISTICAS DE CADA VARIABLE

```{python}
# Visualización de los datos numéricos
columnas_numericas = dfnum.columns.tolist()
sns.set(style="darkgrid")
for col in columnas_numericas:
    sns.distplot(dfnum[col])
    plt.title(col)
    plt.show()
```

## ¿TIENE SENTIDO INCLUIR A LA VARIABLE KEY, MODE Y TIME_SIGNATURE DENTRO DE LAS VARIABLES NUMERICAS O DEBERÍAN SER VARIABLES CATEGORICAS?

### Medidas de resumen para variables categoricas

```{python}
dfcat.describe()
```

```{python}
dfcat.columns
```

## 'id' y 'id_artists' son variables que no son relevantes para el analisis 

```{python}
dfcat[['name', 'artists']].mode()
```

```{python}
dfcat[['release_date']].mode()
```

```{python}
dfcat['release_date'].median()
```

## DESCRIBIR ESTOS ESTADISTICOS, NO TENEMOS UN GRAFICO QUE PUEDE DESCRIBIR ESTAS VARIABLES

### **Tratamiento de Datos Atípicos y Estadísticas Descriptivas**

```{python}
# División de variables numéricas y categóricas
dfnum = tracks.select_dtypes(include=['float64', 'int64'])
dfcat = tracks.select_dtypes(exclude=['float64', 'int64'])
```

```{python}
dfnum.head(5)
```

-----

```{python}
dfcat.head(5)
```

```{python}
dfcat.info()
```

```{python}
print('Variables categóricas', dfcat.shape)
print('Variables numéricas', dfnum.shape)
```

```{python}
# Convertimos la variable 'release_date' a datetime64[ns]
dfcat['release_date'] = pd.to_datetime(dfcat['release_date'], format="%Y-%m-%d")
```

## Tratamiento de datos atípicos

#### Datos numéricos

```{python}
descriptivesMax_num = dfnum.describe(percentiles = list(np.arange(0, 1, 0.05)))
descriptivesMax_num
```

```{python}
# Variables que tienen valores atípicos superiores
descriptivesMax_num.loc['max'] > (descriptivesMax_num.loc['75%'] + (1.5* (descriptivesMax_num.loc['75%']-descriptivesMax_num.loc['25%']) ) )
```

```{python}
descriptivesMin = dfnum.describe(percentiles = list( np.arange(0, 1, 0.05)) )
descriptivesMin
```

```{python}
# Variables que tienen valores atípicos inferiores
descriptivesMin.loc['min'] < ( descriptivesMin.loc['25%'] + (1.5* (descriptivesMax_num.loc['75%']-descriptivesMax_num.loc['25%']) ) ) 
```

```{python}
dfnum.describe().quantile(0.5)
```

```{python}
dfnum.columns
```

Variables categóricas (con representacion numérica): \
explicit, key y mode. 

```{python}
# Variables con valores atípicos
dfnum_outlier = dfnum[['popularity', 'duration_ms', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness',
       'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']]
```

```{python}
dfnum_outlier.describe()
```

```{python}
dfnum.columns
```

```{python}
columnas = ['popularity', 'duration_ms', 'danceability', 'energy', 'loudness',
       'speechiness', 'acousticness', 'instrumentalness', 'liveness',
       'valence', 'tempo', 'time_signature']
for col in columnas:
    dfnum_outlier.boxplot(column = [col])
    plt.title(col)
    plt.show()
```

```{python}
# Podemos definir una función que haga lo mismo para cualquier columna numérica
def loc_outliers(df, columna):
  q1 = df[columna].quantile(0.25)
  q3 = df[columna].quantile(0.75)
  iqr = q3 - q1
  ul = q3 + 1.5*iqr
  ll = q1 - 1.5*iqr
  return (df[columna] > ul) | (df[columna] < ll) 
```

```{python}
# Define una función que encuentre todos los outliers por exceso
def loc_outliers_exceso(df, columna):
  q1 = df[columna].quantile(0.25)
  q3 = df[columna].quantile(0.75)
  iqr = q3 - q1
  ul = q3 + 1.5*iqr
  return (df[columna] > ul)

# Define una función que encuentre todos los outliers por defecto
def loc_outliers_defecto(df, columna):
  q1 = df[columna].quantile(0.25)
  q3 = df[columna].quantile(0.75)
  iqr = q3 - q1
  ll = q1 - 1.5*iqr
  return (df[columna] < ll)
```

```{python}
# Reemplazamos todos los outliers por exceso de la columna "antiguedad" por el máximo valor No outlier
for col in columnas:
    dfnum_outlier.loc[loc_outliers_exceso(dfnum_outlier, col)] = dfnum_outlier.loc[loc_outliers_exceso(dfnum_outlier, col)==False, col].max()
    dfnum_outlier.loc[loc_outliers_defecto(dfnum_outlier, col)] = dfnum_outlier.loc[loc_outliers_defecto(dfnum_outlier, col)==False, col].min()
```

```{python}
# Volvemos a generar boxplots para verificar imputaciones
for col in columnas:
    dfnum_outlier.boxplot(column = [col])
    plt.title(col)
    plt.show()
```

```{python}
# Graficamos el Q-Q plot de cada variable
# ¿Qué variables aparentemente siguen una distribución normal/gaussiana?
import pylab 
import scipy.stats as stats

# La funcion select_dtypes genera un data frame formado únicamente por
# columnas del tipo indicado como argumento
for col in dfnum_outlier.select_dtypes('number').columns:
  stats.probplot(dfnum_outlier[col], dist = "norm", plot = plt)
  plt.title(col)
  pylab.show()
```

